{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.425855513307985,
  "eval_steps": 200,
  "global_step": 400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.060836501901140684,
      "grad_norm": 1.6866116523742676,
      "learning_rate": 0.00019636363636363636,
      "loss": 2.897,
      "step": 10
    },
    {
      "epoch": 0.12167300380228137,
      "grad_norm": 0.2169041633605957,
      "learning_rate": 0.00019232323232323232,
      "loss": 0.2554,
      "step": 20
    },
    {
      "epoch": 0.18250950570342206,
      "grad_norm": 0.1461765319108963,
      "learning_rate": 0.0001882828282828283,
      "loss": 0.1792,
      "step": 30
    },
    {
      "epoch": 0.24334600760456274,
      "grad_norm": 0.1109306812286377,
      "learning_rate": 0.00018424242424242427,
      "loss": 0.1363,
      "step": 40
    },
    {
      "epoch": 0.3041825095057034,
      "grad_norm": 0.08989128470420837,
      "learning_rate": 0.00018020202020202023,
      "loss": 0.1008,
      "step": 50
    },
    {
      "epoch": 0.3650190114068441,
      "grad_norm": 0.045199017971754074,
      "learning_rate": 0.00017616161616161618,
      "loss": 0.0919,
      "step": 60
    },
    {
      "epoch": 0.42585551330798477,
      "grad_norm": 0.03830556198954582,
      "learning_rate": 0.00017212121212121213,
      "loss": 0.0868,
      "step": 70
    },
    {
      "epoch": 0.4866920152091255,
      "grad_norm": 0.03944766893982887,
      "learning_rate": 0.00016808080808080808,
      "loss": 0.0832,
      "step": 80
    },
    {
      "epoch": 0.5475285171102662,
      "grad_norm": 0.045690808445215225,
      "learning_rate": 0.00016404040404040403,
      "loss": 0.0862,
      "step": 90
    },
    {
      "epoch": 0.6083650190114068,
      "grad_norm": 0.03996285796165466,
      "learning_rate": 0.00016,
      "loss": 0.0795,
      "step": 100
    },
    {
      "epoch": 0.6692015209125475,
      "grad_norm": 0.03913366422057152,
      "learning_rate": 0.00015595959595959597,
      "loss": 0.078,
      "step": 110
    },
    {
      "epoch": 0.7300380228136882,
      "grad_norm": 0.0434127002954483,
      "learning_rate": 0.00015191919191919192,
      "loss": 0.0824,
      "step": 120
    },
    {
      "epoch": 0.7908745247148289,
      "grad_norm": 0.038444168865680695,
      "learning_rate": 0.0001478787878787879,
      "loss": 0.0809,
      "step": 130
    },
    {
      "epoch": 0.8517110266159695,
      "grad_norm": 0.03568209707736969,
      "learning_rate": 0.00014383838383838385,
      "loss": 0.0691,
      "step": 140
    },
    {
      "epoch": 0.9125475285171103,
      "grad_norm": 0.03368266299366951,
      "learning_rate": 0.0001397979797979798,
      "loss": 0.075,
      "step": 150
    },
    {
      "epoch": 0.973384030418251,
      "grad_norm": 0.0410967692732811,
      "learning_rate": 0.00013575757575757578,
      "loss": 0.0705,
      "step": 160
    },
    {
      "epoch": 1.0304182509505704,
      "grad_norm": 0.05033815652132034,
      "learning_rate": 0.00013171717171717173,
      "loss": 0.0705,
      "step": 170
    },
    {
      "epoch": 1.091254752851711,
      "grad_norm": 0.03610198199748993,
      "learning_rate": 0.00012767676767676768,
      "loss": 0.0728,
      "step": 180
    },
    {
      "epoch": 1.1520912547528517,
      "grad_norm": 0.041626933962106705,
      "learning_rate": 0.00012363636363636364,
      "loss": 0.072,
      "step": 190
    },
    {
      "epoch": 1.2129277566539924,
      "grad_norm": 0.03231820836663246,
      "learning_rate": 0.0001195959595959596,
      "loss": 0.0694,
      "step": 200
    },
    {
      "epoch": 1.2737642585551332,
      "grad_norm": 0.034092336893081665,
      "learning_rate": 0.00011555555555555555,
      "loss": 0.0663,
      "step": 210
    },
    {
      "epoch": 1.3346007604562737,
      "grad_norm": 0.03357228264212608,
      "learning_rate": 0.00011151515151515153,
      "loss": 0.0667,
      "step": 220
    },
    {
      "epoch": 1.3954372623574145,
      "grad_norm": 0.04237636923789978,
      "learning_rate": 0.00010747474747474748,
      "loss": 0.0734,
      "step": 230
    },
    {
      "epoch": 1.456273764258555,
      "grad_norm": 0.03261762112379074,
      "learning_rate": 0.00010343434343434344,
      "loss": 0.071,
      "step": 240
    },
    {
      "epoch": 1.5171102661596958,
      "grad_norm": 0.034827396273612976,
      "learning_rate": 9.939393939393939e-05,
      "loss": 0.0728,
      "step": 250
    },
    {
      "epoch": 1.5779467680608366,
      "grad_norm": 0.04131757840514183,
      "learning_rate": 9.535353535353537e-05,
      "loss": 0.0729,
      "step": 260
    },
    {
      "epoch": 1.6387832699619773,
      "grad_norm": 0.03737423196434975,
      "learning_rate": 9.131313131313132e-05,
      "loss": 0.0745,
      "step": 270
    },
    {
      "epoch": 1.6996197718631179,
      "grad_norm": 0.03749212250113487,
      "learning_rate": 8.727272727272727e-05,
      "loss": 0.0695,
      "step": 280
    },
    {
      "epoch": 1.7604562737642584,
      "grad_norm": 0.03967485949397087,
      "learning_rate": 8.323232323232324e-05,
      "loss": 0.0689,
      "step": 290
    },
    {
      "epoch": 1.8212927756653992,
      "grad_norm": 0.05203229933977127,
      "learning_rate": 7.919191919191919e-05,
      "loss": 0.0671,
      "step": 300
    },
    {
      "epoch": 1.88212927756654,
      "grad_norm": 0.04021722823381424,
      "learning_rate": 7.515151515151515e-05,
      "loss": 0.0666,
      "step": 310
    },
    {
      "epoch": 1.9429657794676807,
      "grad_norm": 0.0679311454296112,
      "learning_rate": 7.111111111111112e-05,
      "loss": 0.0719,
      "step": 320
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.06022707372903824,
      "learning_rate": 6.707070707070707e-05,
      "loss": 0.0679,
      "step": 330
    },
    {
      "epoch": 2.0608365019011408,
      "grad_norm": 0.038810793310403824,
      "learning_rate": 6.303030303030302e-05,
      "loss": 0.0652,
      "step": 340
    },
    {
      "epoch": 2.1216730038022815,
      "grad_norm": 0.054860759526491165,
      "learning_rate": 5.8989898989898996e-05,
      "loss": 0.0664,
      "step": 350
    },
    {
      "epoch": 2.182509505703422,
      "grad_norm": 0.03560612350702286,
      "learning_rate": 5.494949494949495e-05,
      "loss": 0.0707,
      "step": 360
    },
    {
      "epoch": 2.2433460076045626,
      "grad_norm": 0.047198694199323654,
      "learning_rate": 5.090909090909091e-05,
      "loss": 0.0693,
      "step": 370
    },
    {
      "epoch": 2.3041825095057034,
      "grad_norm": 0.039092957973480225,
      "learning_rate": 4.686868686868687e-05,
      "loss": 0.0728,
      "step": 380
    },
    {
      "epoch": 2.365019011406844,
      "grad_norm": 0.04149780049920082,
      "learning_rate": 4.282828282828283e-05,
      "loss": 0.0714,
      "step": 390
    },
    {
      "epoch": 2.425855513307985,
      "grad_norm": 0.039897408336400986,
      "learning_rate": 3.878787878787879e-05,
      "loss": 0.0696,
      "step": 400
    }
  ],
  "logging_steps": 10,
  "max_steps": 495,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.5442933210834534e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
