import json
import re
from collections import defaultdict
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from datasets import load_dataset
import swanlab

# =========================
# å®ä½“æå–å‡½æ•°
# =========================
def extract_entities_from_text(output_text):
    """
    ä»æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬ä¸­è§£æå‡ºå®ä½“ï¼Œå‡è®¾è¾“å‡ºæ˜¯JSONæ ¼å¼
    """
    entities = defaultdict(list)
    try:
        json_part = re.search(r"\{.*\}", output_text, re.S)
        if json_part:
            parsed = json.loads(json_part.group())
            for k, v in parsed.items():
                if isinstance(v, list):
                    entities[k] = v
    except Exception:
        pass
    return entities

# =========================
# è®¡ç®—è¯çº§F1
# =========================
def compute_f1(y_true_all, y_pred_all):
    f1_results = {}
    all_entity_types = set(y_true_all.keys()) | set(y_pred_all.keys())
    for etype in all_entity_types:
        y_true = set(y_true_all.get(etype, []))
        y_pred = set(y_pred_all.get(etype, []))
        tp = len(y_true & y_pred)
        fp = len(y_pred - y_true)
        fn = len(y_true - y_pred)
        precision = tp / (tp + fp + 1e-9)
        recall = tp / (tp + fn + 1e-9)
        f1 = 2 * precision * recall / (precision + recall + 1e-9)
        f1_results[etype] = {"precision": precision, "recall": recall, "f1": f1}
    return f1_results

# =========================
# ä¸»å‡½æ•°
# =========================
def main():
    # SwanLab åˆå§‹åŒ–
    run = swanlab.init(
        project="tcm-ner-qlora",
        experiment_name="NER_Eval",
        description="Evaluate TCM NER QLoRA model with attention_mask and pad_token fix",
    )

    # =========================
    # åŠ è½½æ¨¡å‹å’Œ tokenizer
    # =========================
    model_dir = "./tcm_ner_qlora_model"
    tokenizer = AutoTokenizer.from_pretrained(model_dir)
    model = AutoModelForCausalLM.from_pretrained(
        model_dir,
        device_map="auto",
        torch_dtype=torch.bfloat16
    )
    model.eval()
    # è®¾ç½® pad_token_id é¿å…è­¦å‘Š
    model.config.pad_token_id = tokenizer.eos_token_id

    # =========================
    # åŠ è½½æµ‹è¯•é›†
    # =========================
    test_dataset = load_dataset("json", data_files={"test": "test.jsonl"})["test"]

    # =========================
    # æ¨ç† & ç»Ÿè®¡ F1
    # =========================
    y_true_all = defaultdict(list)
    y_pred_all = defaultdict(list)

    for idx, sample in enumerate(test_dataset):
        input_text = f"{sample['instruction']}\n{sample['input']}\nç­”ï¼š"
        true_entities = sample["output"]

        # tokenizeï¼Œç”Ÿæˆ attention_mask
        encoding = tokenizer(
            input_text,
            return_tensors="pt",
            padding=True,
            truncation=True
        ).to(model.device)

        with torch.no_grad():
            outputs = model.generate(
                input_ids=encoding["input_ids"],
                attention_mask=encoding["attention_mask"],
                max_new_tokens=256,
                temperature=0.0,
                do_sample=False,
                pad_token_id=model.config.pad_token_id
            )

        pred_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
        pred_entities = extract_entities_from_text(pred_text)

        # æ”¶é›†å®ä½“
        for etype, ents in true_entities.items():
            y_true_all[etype].extend(ents or [])
        for etype, ents in pred_entities.items():
            y_pred_all[etype].extend(ents or [])

        # å¯è§†åŒ–è¿›ç¨‹
        if (idx + 1) % 10 == 0:
            run.log({"progress": (idx + 1) / len(test_dataset)})

    # =========================
    # è®¡ç®— F1 å¹¶æ‰“å°
    # =========================
    f1_results = compute_f1(y_true_all, y_pred_all)
    print("\nğŸ“Š æµ‹è¯•é›†æ¯ç±»å®ä½“F1:")
    for etype, scores in f1_results.items():
        print(f"{etype:10s} | P={scores['precision']:.4f} R={scores['recall']:.4f} F1={scores['f1']:.4f}")
        run.log({
            f"F1/{etype}": scores["f1"],
            f"Precision/{etype}": scores["precision"],
            f"Recall/{etype}": scores["recall"]
        })

    run.finish()
    print("âœ… è¯„ä¼°å®Œæˆï¼ŒSwanLab å¯è§†åŒ–ç»“æŸã€‚")

if __name__ == "__main__":
    main()
